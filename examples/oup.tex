\documentclass[12pt,titlepage]{article}   
\usepackage[body={6.3in,8.8in},top=.6in]{geometry}
\usepackage{endnotes} 
\usepackage{times}  
\usepackage{tipa}         
\usepackage{covington}
\usepackage{amssymb}  
\usepackage{pifont}  
\usepackage{epsfig} 
\usepackage{epic}
\usepackage{eepic}
%\usepackage{fancyheadings}
\usepackage{fullpage}
%\pagestyle{fancy}
%\headrulewidth{0pt}
%\lhead{} \lfoot{}
%\chead{} \cfoot{}
%\rhead[\rm\thepage]{\rm\thepage} \rfoot{}

%\let\footnote=\endnote

% \usepackage{doublespace}
%\setstretch{1.67}

\begin{document}

\title{Phonology as Cognition}

\author{Mark Hale\\ Concordia University, Montr\'{e}al\\hale1@alcor.concordia.ca \and  Charles 
Reiss\\Concordia University, Montr\'{e}al\\reiss@alcor.concordia.ca}
\date{}

\maketitle

% \thispagestyle{empty}

\section{{\sc Form and substance in phonology}}
This paper attempts to ground phonology within psychology. That is, we are interested in phonology as 
a branch of the study of mental representation, the psychology of mind. In order to develop this `phonology 
of mind' we need to understand the relationship between form and substance in linguistic representation. 
A coherent account of this distinction has yet to be proposed for either phonology 
or syntax. We attempt to contribute to this necessary inquiry 
in the domain of phonology by first defining `form' and `substance', then 
critiquing some recent work which implicitly or explicitly touches on the 
relationship between the two. We will argue that  current trends in phonology 
fail to offer a coherent conception of form and substance and are also inconsistent with 
basic principles of science. Since we  are not proposing a complete alternative 
model of phonology, we invite the reader to reflect on how our proposals could 
be implemented or on how our assumptions (which we believe are widely shared 
in principle, if not in practice) should be modified.

It has proven quite useful for linguists to conceive of a grammar  as a relationship 
between i) a set of symbols---entities such as features and variables, 
constituents like syllables, feet, NPs, {\em etc.}; and ii) a set of 
computations---operations whose operands are drawn from the set of symbols, such as concatenation, 
deletion, {\em etc}. The set of symbols and relations together describe the formal properties of the system. 
Relevant questions  in discussing formal properties include  `Is the system  rule- and/or constraint-based?'; 
`Do operations apply serially or in parallel?'; and `Are there limits on the number of operands referred to 
in the course of a given phonological computation?'

The issue of substance essentially arises only with respect to the 
set of symbols and the extent to which their  behavior in phonological computation  is driven by what they  symbolize. For the sake of simplicity we restrict ourselves in this discussion
to the set of phonological primitives 
known as distinctive features and to the representations which can be defined as 
combinations of distinctive features.  

We will concentrate in this paper on this notion  of substance in phonological representation. In brief the question we are interested in 
is the following: 
\begin{itemize}
\item[(1)]{Do the phonetic correlates ({\em i.e.}, the substance) of a particular distinctive feature 
or feature bundle  have any non-arbitrary bearing on how that feature or feature 
bundle is treated by the computational system?}
\end{itemize}


\noindent  It is trivial to show that 
languages differ in that their computational systems treat specific features 
or feature bundles differently ---  
for example, Standard German has coda obstruent devoicing and English does not. From 
this 
we can conclude that languages {\em can} treat the same symbols differently. A 
more challenging problem arises when we find an apparent example of 
cross-linguistically universal, 
seemingly non-arbitrary treatment of a feature or feature bundle. 
In such cases we must ask ourselves the following:


\begin{itemize}
\item[(2)]{Is the observed pattern a reflection of substantive constraints on the computational system
(i.e., the grammar), or is the pattern due  to other causes?}
\end{itemize}

\noindent Other {\em a priori} plausible causes include, as we shall show in 
what follows,
the process of language change, the nature of the language acquisition device, 
sampling 
errors, {\em etc}. From the standpoint of grammatical theory, factors such as 
sampling 
errors are obviously uninteresting. However, language change and the 
nature of the learning path are also, strictly speaking, not part of grammatical 
theory. The modular approach to linguistics, and  to science in general, 
requires 
that we both model the interactions between related domains, and also sharply 
delineate one domain from another. Occam's razor demands that, in doing so, we 
avoid redundancy and the postulation of unnecessary factors.

Even before proceeding to our argument that generalisations that bear on patterns of phonetic substance are not 
relevant to phonological theory as we define it, we can see that there is potentially much to gain 
from this modular approach in that it posits that universal phonology should be 
studied not just across languages, but also across modalities. What is shared by the phonologies of signed 
and spoken languages? We believe that phonology consists of a set of formal properties ({\em e.g.}, 
organization into syllables and feet, feature spreading processes) that are modality independent 
and thus not based on phonetic substance. The goal of phonological theory should be to discover these formal properties.\footnote{This paper expands on Hale \& Reiss (2000). We are grateful to audiences 
at {\em Montreal-Ottawa-Toronto Phonology Workshop 1998} at the University 
of Ottawa and at the Berkeley Phonology Laboratory, as well as to Noel Burton-Roberts, Morris Halle, Bill Idsardi, Madelyn Kissock, Afton Lewis, Jean-Philippe Marcotte and  
Ida Toivonen for discussion and challenging 
criticism that improved the paper. The authors' names appear in alphabetical order.} Failure to appreciate this goal has resulted in rampant `substance abuse' in the phonological community.

We discuss various aspects of substance abuse in sections 2-5. In section 6, we offer a modest contribution to a substance-free phonology. In section 7, we return to  substance with a discussion of the putative phenomenon of phonetic enhancement in grammars. Section 8 ties together the preceding sections with arguments against functionalist `explanation' in linguistics. We argue that  {\em dysfunctionalist} reasoning fares as well as its better known rival. Section 9 provides a concluding plea for a modular approach to the study of sound patterns in human languages. 


 


\section{{\sc Three examples of substance abuse in grammatical theory}}

\subsection{{\it Positional Faithfulness in Beckman (1997)}} 
Beckman (1997) proposes the constraints in (3a-b) as members of the universal 
constraint set:

\begin{itemize}
\item[(3)]{a. {\sc Ident}-$\sigma_1$(hi)}
\end{itemize}
\vspace{-.3in}

\begin{quotation}
\noindent{A segment in the root-initial syllable in the output and its 
correspondent in the 
input must have identical values for the feature [high].}
\end{quotation}


\begin{itemize}
\item[]{b. {\sc Ident}(hi)}
\end{itemize}
\vspace{-.3in}

\begin{quotation}
\noindent{Correspondent segments in output and input have identical values for 
the feature [high].}
\end{quotation}

\noindent As Beckman explains, this set of constraints allows 
faithfulness 
to a feature, like [high], to be maintained in some contexts, but not others, 
since the 
context sensitive constraint (3a)  can be ranked above a markedness constraint 
that is violated by,  say, the presence of high vowels, *{\sc High}, which in turn 
is 
ranked above the general constraint in (3b). In other words the ranking in 
(4) will allow surface high vowels only in root-initial syllables.

\begin{itemize}
\item[(4)]{{\sc Ident}-$\sigma_1$(hi) $>>$  *{\sc High} $>>$ {\sc Ident}(hi)}
\end{itemize}

\noindent This is assumed to be a welcome result: 

\begin{quotation} \noindent The high ranking of positional faithfulness constraints, 
relative to both the more general {\sc Ident} constraints and markedness constraints, 
yields the result that features and/or contrasts in {\em just those positions which 
are psycholinguistically or perceptually salient} are less susceptible to neutralisation 
than in other locations which are not protected. [Beckman 1997:8. emphasis in 
original.]
\end{quotation}

\noindent Beckman (p.5) cites more than ten psycholinguistic studies to support her 
claim that word-initial material is more salient than medial or final material.\footnote{It is 
unclear whether this generalisation would hold, say, in a language with 
non-initial stress. It is also unclear whether Beckman's extension of psycholinguistic 
findings concerning word-initial syllable to {\em root}-initial syllables is justified.  
However, we will assume, for purposes of this discussion, 
that Beckman has stated the relevant generalizations correctly.} We believe that the correct conclusion 
to be drawn from this psycholinguistic evidence is the {\em exact opposite} of that 
which Beckman draws.\footnote{We wish 
to stress that we are not singling Beckman out for any reason except for the fact that 
her paper appeared recently in a widely read journal and is  well-written and clear in 
its arguments and assumptions.} Encoding the findings of 
psycholinguistic experimentation in the grammar is a mistake because it is possible to achieve the 
same empirical coverage without positing new mechanisms like positional 
faithfulness.\footnote{For other arguments against context-sensitive 
faithfulness see Reiss (1996:315).} Consider the 
following alternative account.

We know that children acquire spoken language primarily on the basis of acoustic input 
from speakers in their environment, with UG providing constraints on the hypothesis 
space.\footnote{It may be a useful idealization to assume that UG does not just constrain 
the learning path, but completely determines it. We suspect that such a position will 
prove most fruitful in sketching an explicit theory of acquisition, but 
justification for this goes beyond the scope of this paper.} We also know that 
phonological contrasts are best distinguished and recalled when occurring in certain 
positions. Imagine a child exposed to a language ${\cal L}_1$ which allows high vowels 
in all syllables --- initial, medial and final. Imagine further that ${\cal L}_1$ has 
initial stress and that stress is realized as relatively increased duration and 
intensity. Given this scenario, it is easy to see that a child 
constructing ${\cal L}_2$ on the basis of ouput from ${\cal L}_1$ could consistently 
fail to acquire a contrast between mid and high vowels in relatively short, quiet 
syllables (those that are non-initial and thus unstressed), but succeed in acquiring 
this distinction in initial syllables, which are stressed and thus longer and louder. 
This type of relationship between ${\cal L}_1$ and ${\cal L}_2$ is known as `sound 
change' (in particular, as a `conditioned merger'). On the other hand, it is highly implausible that 
an acquirer would consistently fail 
to correctly analyze the mid/high contrast in longer, louder (stressed) syllables, yet successfully analyze 
the contrast in relatively short, quiet syllables. Note that this implausibility is 
independent of our view of the nature of UG.

We see therefore that the existence of positional faithfulness phenomena can be 
understood as merely reflecting 
the nature of the learning situation and not a reflection of any grammatical
principle:\footnote{This idea is discussed more thoroughly in 
Hale (forthcoming).}

\begin{itemize}
\item[(5)]{If the acoustic cues of a given contrast in the target language are correctly analyzed by the acquirer
in a context where they are relatively weak, they will also be analyzed correctly in a context where they are relatively strong.}
\end{itemize}

\noindent Note that (5) is essentially definitional, since the strength, or acoustic salience, of a contrast is just a measure of how 
easy it is to perceive. What is most important to understand is that the 
theory proposed here is not meant to \textit{replace} a synchronic account of 
the data. So, the best synchronic analysis must somehow be able to generate vowel neutralization in 
noninitial syllables. (5) is meant to guide us in choosing a theory of grammar in which to couch that 
synchronic account, but (5) is not part of the grammar. Whatever theory of phonology one adopts, it must be able to synchronically 
generate the type of patterns that Beckman describes, but the predictions generated by the correct theory, {\em qua} 
phonological theory, need not replicate the predictions derivable from (5). 

By adopting the view of sound change proposed here, we see that many supposedly
phonological tendencies, or markedness patterns, are actually emergent properties, that is epiphenomenal. 
`Positional faithfulness' is due, not to the nature of {\em phonology}, but to the `sifting 
effect' of acquisition on the incidental, arbitrary nature of the phonetic substance. Since effects such as those observed by Beckman 
already have a coherent extragrammatical account within acquisition theory (and it is necessary, in 
any event, to have an acquisition theory),
building positional faithfulness into a theory of universal 
phonology is a misuse, or abuse, of phonetic substance in theory construction.

\subsection{{\it /r/-insertion in McCarthy (1993)}}
McCarthy's (1993) discussion of intervocalic {\em r}-insertion in Massachusetts 
English 
is fairly well-known, so an example should be sufficient for illustration. In 
this 
dialect, an underlying sequence like {\em Wanda arrived} is realized with a 
`linking' 
[r]: {\em Wanda[r] arrived}. As McCarthy himself notes (and as discussed by 
LaCharit\'{e} 
\& Paradis 1993 and  Halle \& Idsardi 1997) ``r is demonstrably not the default 
consonant 
in English'' (189). That is, it is not the maximally unmarked consonant that an 
OT 
account predicts would emerge in such a situation. In order to account for the 
insertion 
of [r] McCarthy proposes a special {\em rule} of {\em r}-insertion: ``a 
phonologically 
arbitrary stipulation, one that is outside the system of Optimality'' (190). 
There are 
several problems with this proposal, many of which are insightfully discussed by 
Halle 
\& Idsardi. However, we propose that one of their criticisms requires 
elaboration. Halle 
\& Idsardi rightly point out that ``reliance on an arbitrary stipulation that is 
outside the 
system of Optimality is equivalent to giving up on the whole enterprise (337),'' but 
these authors do not discuss what we consider to be the most important 
point: grammars do contain arbitrary processes.  McCarthy's grammar  has  an arbitrary 
component (containing rules 
like   {\em r}-insertion) and a non-arbitrary component (containing the substantive OT constraints).  Such a theory is empirically 
non-distinct from the theory we propose below, which posits that {\em all} grammatical computations  are arbitrary with respect to 
phonetic substance. This is because the set of phenomena predicted to
exist by our theory (with only arbitrary processes) is identical to the set of phenomena predicted to exist by McCarthy's
theory (with both non-arbitrary and arbitrary processes). Since McCarthy must adopt a model which allows arbitrary phenomena (like {\em r}-insertion), the addition to the theory of a special subcomponent to account for 
alleged `non-arbitrary' phenomena violates Occam's
Razor.

The diachronic source of {\em r}-insertion  is transparent---the relevant 
dialects also 
exhibit {\em r}-deletion in codas, so insertion reflects rule-inversion 
triggered by 
hypercorrection.  Again, the diachronic facts do not make a synchronic account 
unnecessary, but they show us that basically idiosyncratic historical events 
affect 
specific grammars --- and, in part, how they may do so.

\subsection{{\it Structural constraints on non-structures}}

Perhaps one of the most problematic cases of substance abuse we have come
across is McCarthy's (1996) appeal to parameterized constraints to account for opacity
effects in
Hebrew spirantization by invoking  the notion of constraint schema. McCarthy
makes some reasonable simplifying assumptions in this first attempt:

\begin{quotation}

\noindent I will assume that every constraint is a prohibition or negative
target defined over no more than two segments, $\alpha$ and $\beta$. That is,
the canonical constraint is something like *\{$\alpha$,$\beta$\}, with
appropriate conditions imposed on $\alpha$ and $\beta$.
These conditions are as follows:            

\begin{itemize}
\item[(i)] a specification of the featural properties of $\alpha$ and $\beta$
as individual segments.
\item[(ii)] a specification of the linear order relation between $\alpha$ and
$\beta$ ($\alpha < \beta$, $\beta < \alpha$, or both in the case of
mirror-image rules \ldots
\item[(iii)] a specification of the adjacency relation between $\alpha$ and
$\beta$ (e.g., strict adjacency, vowel-to-vowel adjacency \ldots
\end{itemize}

The decomposition of the conditions imposed by a phonological
constraint will be crucial in accounting for the range of opacity phenomena.
Even more important, though, is this: each condition---the featural composition
of $\alpha$, the featural composition of $\beta$, linear order and
adjacency---must also name the level (underlying, surface, or either) at which
it applies. Correspondence Theory allows us to make sense of conditions
applying at one level or the other. As a bookkeeping device, I will state the  
constraints in the form of a table \ldots

\end{quotation}

\noindent We reproduce here the schema-based constraint  that McCarthy proposes
to account for Tiberian Hebrew Post-vocalic Spirantization.


\Large
\begin{itemize}
\item[(6)]{Constraint for opacity in Hebrew spirantization (McCarthy 1996:223)}
\end{itemize}


\begin{tabular}{l|l|l|} \cline{2-3}
\hspace{.15in}* & Condition & Level \\ \hline \hline
\hspace{-.14in} \vline \hspace{.15in} $\alpha$ & V & Indifferent \\ \hline
\hspace{-.14in} \vline \hspace{.15in}  $\beta$ & [-son, -cont] & Surface \\ \hline
\hspace{-.14in} \vline \hspace{.15in} Linear Order & $\alpha > \beta$ & Indifferent \\ \hline
\hspace{-.14in} \vline \hspace{.15in}  Adjacency & Strict & Indifferent \\ \hline
\end{tabular}   
\vspace{.1in}


\normalsize


\noindent As McCarthy says
``In correspondence terms, the meaning of this constraint is this: the constraint is violated if a surface
stop $\beta$ or its underlying correspondent is immediately preceded by a vowel.''

As pointed out in Reiss (1997), this powerful constraint type has several problems.
First, it compromises the OT notion of a universal, innate constraint set by allowing
apparently language-specific
parameterized constraints. This may not be a serious problem, since it
represents an attempt to define the form of possible constraints. In other
words, McCarthy could be interpreted as  presenting a theory in which the
intensional description of the set of constraints is  universal, but languages
vary in which constraints they actually incorporate (based on evidence
presented to the learner).\footnote{McCarthy does not explicitly make this
argument, but it seems to us to be a better theory than the standard OT claim
that all constraints are literally present in all grammars. Of course, adopting
our suggested interpretation will force OT practitioners to revise their views
on acquisition and, especially, {\it emergence of the unmarked}. This view of
OT would also make it much closer to a theory of  learned rules.}

Most relevant to our present purposes, however, is the fact that such    
constraints undermine  implicit and explicit
appeal to phonetic grounding of well-formedness constraints in McCarthy's
work. For example, McCarthy and Prince (1995:88) refer to a constraint *VgV as the
``phonologization of Boyle's Law''. It is incoherent to argue that a constraint
is motivated by the facts of phonetics, when the structures which violate this
constraint need not be  surface  structure strings. In fact, they need not 
exist as strings at {\it any level of representation}.


\section{{\sc Neo-Saussureanism}}
The conclusion we wish to draw from the above examples and many others like them 
is 
that the best way to gain an understanding of the computational system of 
phonology is 
to assume that the phonetic substance (say, the spectral properties of sound waves) that leads to the construction   of phonological entities (say,  feature matrices)  {\em never} reflects  
how 
the phonological entities are treated by the computational system. The computational system treats features and the like as arbitrary symbols. What this means is that many of the so-called {\em phonological 
universals} (often 
discussed under the rubric of markedness) are in fact epiphenomena deriving from 
the 
interaction of extragrammatical factors like acoustic salience and the nature of 
language change. It is not surprising that even among its proponents, markedness 
`universals' are usually stated as `tendencies'. If our goal as generative 
linguists 
is to define the set of {\em computationally possible} human grammars, 
`universal 
tendencies' are irrelevant to that enterprise. 


We therefore propose extending the Saussurean notion of the arbitrary 
nature of linguistic signs to the treatment of phonological representations by 
the 
phonological computational system. Phonology is not and should not be grounded 
in 
phonetics since the facts which phonetic grounding is meant to explain can be 
derived 
without reference to {\em phonology}. Duplication of the principles of acoustics and 
acquisition 
inside the grammar constitutes a violation of Occam's razor and thus must be 
avoided. 
Only in this way will we be able to correctly characterize the universal aspects 
of 
phonological computation.


John Ohala ({\em e.g.}, 1990) has done the most to demonstrate that many so-called markedness tendencies can be explained on phonetic grounds and thus should not be explained by principles of grammar. Examples discussed by Ohala include  patterns of assimilation and the contents of phonemic inventories. For an extensive bibliography on this topic see Ohala (1998). We differ from Ohala in our use of the term `phonology'  (which for him covers {\em all} aspects of the sound systems of human language) but wholeheartedly endorse his approach. 


\subsection{{\it Substance in {\em SPE}}}
It is obvious that our proposal runs contrary to most of the discussion in 
Chapter 9 of {\em SPE} (Chomsky and Halle 1968). This chapter starts out with an 
`admission' that the theory developed in the earlier chapters is seriously 
flawed:
\begin{quotation}
\noindent The problem is that our approach to features, to rules and to 
evaluation has been overly formal. Suppose, for example, that we were 
systematically to interchange features or to replace [$\alpha$F] by [-$\alpha$F] 
(where $\alpha$ is +, and F is a feature) throughout our description of English 
structure. There is nothing in our account of linguistic theory to indicate that 
the result would be the description of a system that violates certain principles 
governing human languages. To the extent that this is true, we have failed to 
formulate the principles of linguistic theory, of universal grammar, in a 
satisfactory manner. In particular, we have not made use of the fact that the 
features have intrinsic content. [400]. 
\end{quotation}

\noindent Later in the chapter Chomsky and Halle themselves acknowledge that, with the above-quoted
assertion, they are on the wrong track:

\begin{quotation}
\noindent It does not seem likely that an elaboration of the theory along the 
lines just reviewed will allow us to dispense with phonological processes that 
change features fairly freely. The second stage of the Velar Softening Rule of 
English (40) and of the Second Velar Palatalization of Slavic strongly suggests 
that the phonological component requires wide latitude in the freedom to change 
features, along the lines of the rules discussed in the body of this book [428].
\end{quotation}

\noindent In other words, Chomsky \& Halle ultimately recognize that the truly important parts of the phonology, in the sense of the ones that are unnatural, are those which cannot be derived from functional considerations of naturalness. This conclusion is echoed elsewhere: ``Where properties of language can be explained on such `functional' grounds, they provide no revealing insight into the nature of mind. Precisely because the explanations proposed here are `formal explanations,' precisely because the proposed principles are not essential or even natural properties of any imaginable language, they provide a revealing mirror of the mind (if correct)'' (Chomsky 1971:44). 



We propose that switching the feature coefficients as described in the 
first quotation might lead to the description of systems that are {\em 
diachronically} impossible human languages (ones that could never arise because of the nature of language change), but not to ones that are {\em 
computationally} impossible. The goal of phonologically theory, as a branch of 
cognitive science, is to categorize what is  a computationally  possible phonology, given the 
computational nature of the phonological component of UG.\footnote{This 
argument, as well as other ideas in this paper, was anticipated by Hellberg 
(1980) See also Burton-Roberts, this volume, section 5.}

\subsection{{\it Computation {\em vs.} Transduction: A Place for Substance}}

It is important to note that the preceding discussion is not meant to imply that the mapping of sound to features is  arbitrary. It is only the treatment of phonological representations within the computation that is arbitrary. Articulatory and acoustic substance {\it are}  related to the representations we construct, but not within the grammar. The nature of this relationship is part of the theory of {\em transduction}---the mapping between the physical and the symbolic (Pylyshyn 1984). As Bregman (1990:3) points out  ``In using the word representations, we are implying the existence of a two-part system: one part forms the representations and another uses them to do such things as calculate \ldots'' Bregman is concerned with the auditory system which does not have an output module -- in discussing language, we also need to model output  transducers that map from surface  (featural) representations to articulatory gesture. For our purposes, Bregman's distinction corresponds to speech  perception (construction of featural representations, ultimately from auditory signals) and grammar, which performs symbolic computation. We know from the existence of visual and auditory illusions that the transduction process is not simple. The perceptual system does not just form a direct record of physical stimuli. As Bregman points out, we know that representations are being constructed, because only then could they be constructed incorrectly, leading  to illusions. 

Pylyshyn (1984) provides the following discussion: ``This, then is the importance of a transducer. By mapping certain classes of physical states of the environment into computationally relevant states of a device [{\it e.g.} a human], the transducer performs a rather special conversion: converting computationally arbitrary physical events  into computational events. A description of a transducer function shows how certain  nonsymbolic physical events are mapped into certain symbolic systems'' (152). Pylyshyn points out that the ``{\it computationally relevant} states are a tiny subset of [a system's] physically discriminable states'' and that the ``former are typically a complex function of the latter'' (150). In (7) we paraphrase Pylyshyn's  criteria for a psychological transducer (153-4), that is a transducer from physical signals to representations.

\begin{itemize}
\item[(7)]{Criteria for a psychological transducer}
\begin{itemize}
\item{The function carried out by a transducer is itself {\it nonsymbolic}; it is part of the functional architecture of the system.}
\item{A transducer is stimulus bound, operating independent of the cognitive system.}
\item{The behavior of a transducer is described as a function from physical events to symbols:}
\begin{itemize}
\item[a.]{The domain of the function (the input) is couched in the language of physics.}
\item[b.]{The range of the function (the output) must be computationally available, discrete atomic symbols (for example, feature matrices).}
\item[c.]{The transformation from input to output must be follow from the laws of physics.}
\end{itemize}
\end{itemize}
\end{itemize}


\noindent This is where issues of substance arise---the physical aspects of the acoustic signal serve as the input into the transducer function. From that point on, in the manipulations of the constructed symbolic representations, substance is irrelevant to computation. Only the {\it formal} properties of such representations are relevant to the computational system.


  It is worth  contrasting Pylyshyn's well-articulated modular approach to that of  Prince \& Smolensky (1993) who directly reject the kind of extreme formalist position we advocate here. 


\begin{quotation}
\noindent We urge a reassessment of this essentially formalist position. If phonology is separated from the principles of well-formedness (the `laws') that drive it, the resulting loss of constraint and theoretical depth will mark a major defeat for the enterprise [Prince \& Smolensky 1993: 198, see also p.3].
\end{quotation}


\noindent This view of the goals of phonology  stems from a failure to observe  the critical  transducer vs.\ grammar distinction, that is, from extensive `substance' abuse. It is also at odds with the well-established goals of cognitive science in general:

\begin{quotation}
\noindent [I]f we confine ourselves to the scientific and intellectual goals of understanding psychological phenomena [as opposed to predicting observed behavior--mh \& cr] one could certainly make a good case for the claim that there is a need to direct our attention away from superficial ``data fitting'' models toward deeper structural theories'' [Pylyshyn 1973:48]. 
\end{quotation}
 
\noindent As our discussion  of markedness below
will indicate, we do not believe  that any
`principles of well-formedness' exist, aside from those that constrain the
set of possible representations. That is, we find that the evidence for markedness based constraints to be unconvincing.
 
The `principles of well-formedness' that Prince \& Smolensky refer to and
adopt as the basis of OT constraints are  merely derived from the
heuristic devices that constitute the intuitions of an experienced
linguist. For example, we may intuitively believe that  a sequence like
[akra]  will  more likely be syllabified as [a.kra] rather than as [ak.ra]
in a
random sample of grammars,
although both syllabifications are found, for example,  in the Ancient
Greek dialects. Lacking information to the contrary, it may be useful
to assume that the more common syllabification is present in a new,
unfamiliar language. This will allow the formulation of hypotheses that
may then be tested, and the guess will turn out to be correct more often
than not, if our intuitions have any basis. However, it is a mistake to
assume that our intuitions reflect the nature of the system we
are studying in any direct manner. The intuition that heavy things fall
faster than light things is very useful when someone drops something from
a window, but the intution needs to be transcended to understand the workings
of gravity.  Heuristics are used by the analyst to make useful
guesses about data, and guesses can be wrong. This is why OT constraints
need to be violable, unlike all other scientific laws. 
                                                                                     
The pervasiveness of such  `data-over-principles'  approaches to phonology can be appreciated by the following quote from an influential pre-OT paper:  ``The goal of phonology is the construction of a theory in which cross-linguistically common  and 
well-established processes emerge from very simple combinations of the descriptive parameters of 
the model'' (McCarthy 1988:84). By concentrating on what is `common', rather than what is possible,  phonology  will provide (or rather has provided) plentiful material for descriptive work at some level of sophistication, but it is  clear that no science should be concerned with making it particularly simple to express that which happens often. The goal of any science is to define a coherent domain of inquiry and to establish a common vocabulary for {\em all} events in that domain. This involves reducing  the common {\em and} the  rare events ({\em e.g.}, planetary motion and the Big Bang) to special cases of an abstract set of primitive notions. All of this suggests that while a change of course for phonological theory was definitely needed in the early nineties,  Optimality Theory has been a change in exactly the wrong direction.



\subsection{{\it Acoustophilia: a warning}}

Sapir (1925:37) points out that ``it is a great fallacy to think of the articulation of a speech sound 
as [merely] a motor habit''. A corresponding error is committed in many of the studies 
(e.g., Flemming 1995) that argue for the increased use of acoustic information to model
human phonological computation.  This work tends to establish  units of analysis in
terms of measurements taken over the acoustic signal itself. We believe that this
technique shows the negative effects of `acoustophilia' -- the mental state
arising from the deep and abiding satisfaction which comes from having
{\em something} concrete to measure, in this case the acoustic signal. There is, we believe,
a fairly serious difficulty with such an approach:  we know with a great
deal of confidence that human perception  does not show the kind
of direct   dependency on the signal which the methodology of the acoustophiliacs requires.\footnote{Since 
phonetic substance provides the raw material for phonological theory construction, selective use of 
fine-grained acoustic  data can give rise to insights into the nature of phonological 
computation.  We recognize the significant body of work done on the phonetics/phonology 
interface with reference to acoustic studies. Keating (1988), which uncovers interesting phonetic regularities, 
but maintains a theory of phonology which makes no direct reference to this phonetic substance, is a brilliant 
example.} This attitude towards the study of language echoes the overly  positivist brand of empiricism adopted 
by the behaviorists, an attitude that was discredited already in the nineteen fifties.

An example may make this clearer. Flemming 1995 argues from an examination of
F$_2$ interactions in an experimental setting that it is necessary to have the
grammar generate a statistical pattern which forms a reasonable match to his
experimental results. A parallel from the field of the cognition of vision would examine the
properties of an image as measured with, e.g., a photometer, and require of us
that our `grammar of vision' generate a representation like that measured on
the page. So, in Figure 1 below, it would require -- since the triangle we see is
of precisely the same color and brightness as the background (as can be verified
by the use of a photometer) -- that we construct a   human visual system that does {\em not} see the triangle  projecting from the page.
This is of course the wrong result -- the human visual system, given the input
in Figure 1, constructs a  `percept' which is very different from the patterns we might infer from  photometric readings (see Hoffman 1998).

\begin{figure}[htb]
\begin{center}
\epsfig{figure=illusion-1b.eps}
\end{center}
\caption{Triangle constructed by  visual system.}
\end{figure}

\noindent The difficulty that this presents to more acoustically-oriented approaches
to {\em phonology} is fairly obvious: it is often claimed, on the basis of
some physical measurement of the signal, that something is `difficult' or `easy'
to perceive (auditorily), `salient' or not so salient. Again, note that the edges and inside of the perceived triangle have absolutely no physical properties to distinguish them from the background. What the visual example
in Figure 1 shows us is that measurements taken over the raw data
presented to the human auditory system should not be taken as direct evidence for what kind
of data actually arrives at the {\it linguistic} processing system. 

Turning to the domain of auditory perception, it is a well known result of psychoacoustics that the relationship between, say, intensity of a signal and {\em perceived} loudness is nonlinear: doubling the physical intensity of a signal does not create a signal that is judged to be twice as loud. 
As we move further from the physical signal, to auditory perception and on to the construction of linguistic representations, things become even less clear. 
In particular,
when several distinct and independent cues interact in the signal (as in the
cases discussed by Steriade 1997), we cannot conclude without detailed and
extremely difficult studies of the nature of auditory perception that we
understand the way these cues interact to form an auditory percept. It is yet more difficult to then determine how these auditory percepts get organized into {\em linguistic} (that is, featural, symbolic) representations. These topics will provide  psychologically oriented phoneticians and their colleagues with challenging research projects for years to come. However, the questions and the answers we hope to get are only distally related to the subject matter of phonology. 


Part of the confusion in this area stems from the fact that  discussion of `output' forms often fails to distinguish between the output of the grammar (a feature-based representation) and, say, the output of the speaker (an acoustic or articulatory event). As demonstrated most clearly by our ability to construct 3D representations based on a black and white pattern on a printed page, there is a vast gap between physical stimuli/outputs and the internal (cognitive) representations that relate to them. Therefore, even if phonologists had a metric of the complexity or difficulty inherent in interpreting or creating certain physical stimuli or outputs (which they do not), it is apparent that there is no reason to believe that such a scale would  translate straightforwardly to a markedness scale for representations. There is no reason to believe that the {\em representation} of the act of pushing a bar of gold is more difficult or complex or marked than the representation of the act of pushing a feather (cf.\ Burton-Roberts, this volume).

\section{{\sc Explanatory Inadequacy}}
What are the implications of our view that phonology should be all form and no 
substance? 
In particular, does this conclusion about the nature of phonological operands 
have any 
positive implications for phonological theory? We think that there is one clear 
conclusion to be drawn. Since, as we have argued, languages appear to vary in 
some 
arbitrary ways (e.g. inserting [r] and not, say, [t]), it is necessary to develop 
a 
theory which allows for such variation. In other words, the child should be 
equipped 
with a universal computational system and a set of primitives that can be 
modified upon 
exposure to positive evidence. For this reason, we believe that current 
versions 
of Optimality Theory, which assume a universal  set of (phonetically) substantive constraints 
(e.g. *{\sc VoicedCoda, Lazy}, {\em etc}.) do not shed light on the nature of grammar. A 
set of constraint 
templates, with principles of modification from which the learner can construct 
the 
necessary constraint inventory for the target language may prove to be more 
useful. 
Similarly, a  rule-based theory equipped with a set of principles for defining 
possible 
rules would also allow for the type of stipulative, cross-linguistic variation 
we have 
argued is necessary. Note that, given an explicit theory of acquisition, such 
a `nativism {\em cum} constructivism' view of phonology is well-constrained: UG 
delimits the set of possible 
rules or constraints; the data determines which rules or constraints are 
actually constructed. 

In order to appreciate the fact that positing the type of substantive constraint 
found in the the OT literature adds nothing to the explanatory power of 
phonological theory, consider the situation in which a learner finds 
him/herself. Equipped with an OT type UG, a child born into a Standard German speaking 
environment `knows' that voiced coda obstruents are `marked'. However, this 
child never needs to call upon this knowledge to evaluate voiced coda 
obstruents, since there are none in the ambient target language. In any case, by 
making use of positive evidence the child successfully acquires a language like 
German. Born into an English-speaking environment the child again knows that 
voiced coda obstruents are marked. However, the ambient language provides ample 
positive evidence that such sounds are present, and the child must override the 
supposed innate bias against voiced coda obstruents in order  to learn English. 
So, this purported UG-given gift of knowledge is either irrelevant or misleading 
for what needs to be learned. Our substance-free theory of phonology shares with 
OT-type theories a reliance on positive evidence. The two theories have the same 
empirical coverage, since we also assume that both English and German are 
acquired. The difference is that we leave out of the genetic inheritance `hints' 
that are irrelevant or misleading. We find our solution to be more elegant.
Once again, note that this argument is equally applicable to markedness theories of all types, not just those couched within OT. Since markedness  cannot have any bearing on learnability it is probably irrelevant to any explanatorily adequate theory of grammar. We thus propose banishing markedness from consideration in future linguistic theorizing.\footnote{In fact, there are two distinct types of markedness in the phonological literature. This paper is concerned with substantive markedness. Simplicity or evaluation metrics of the {\em SPE} symbol-counting type can be seen as measuring `formal' markedness. We believe that the best approach to such formal requirements is to build them into the language acquisition device (LAD). Under this view  learners never compare extensionally equivalent grammars for simplicity or economy, they just construct the one that is determined by the LAD. There is, then, no reason to introduce the terms
 `simplicity' and `economy' into the theory since they are contentless labels for arbitrary ({\em i.e.}, not derivable) aspects of the LAD. For a concrete example of how we think the characterization of the LAD should be approached, see Hale \& Reiss, forthcoming.} 

\section{{\sc Discussion}}
The substance abuse
approach has been criticized for cognitive science in general by Pylyshyn (1984:205ff). Pylyshyn describes a box emitting certain recurrent patterns of signals. He then asks what
we can conclude about the nature of the computational mechanism inside the box, based on the observed pattern of output. The answer is that we can conclude nothing, since the
observed patterns may reflect the nature of what is being computed (in his example, the output is a Morse Code rendering of English text, and the observed regularity is the `i before
e, except after c' rule), not the nature of the computer. In Pylyshyn's words ``the observed constraint on [the system's] behavior is due not to its intrinsic capability but to what its
states represent.'' If we are interested in studying the phonology `computer' then we need to distinguish a possible phonological computation from an impossible one. The set of
attested phonological patterns and their distribution may be somewhat skewed by the sifting effect of language change. Real explanation of the nature of phonological computation requires us to see beyond such epiphenomena as `markedness tendencies.'

We believe that the current impregnation of the architecture of the phonological
``virtual machine'' with phonetic substance represents a step backward for 
phonological theory. Phonologists should now call upon their impressive success in amassing 
descriptions of individual phonological `programs' and aim for a more abstract, but deeper 
understanding of phonological computation. 

Pylyshyn's example raises the question of whether constraints are appropriate elements for the construction of grammars at all. By defining grammars via constraints, that is in negative terms, we are drawn into the problem of {\em inductive uncertainty}. In general science works in terms of positive statements. A physical or formal system is defined in positive terms by a list of primitive elements, operations, relationships, {\em etc.} The set of impossible chemical or physical processes, for example, is infinite, and so is the set of impossible linguistic structures. 

Consider the question of hierarchical structure in syntax. Let's imagine that we want to express the claim that all structure is  hierachically organized as a trait of $UG$. How should this proposal be formulated? If one seeks to characterize $UG$ by listing constraints on the set of possible languages, then one might say something like ``Flat structure is not possible''. Since $UG$ is instantiated in real brains,
 it must consist of a finite set of characteristic features. Note however, that, using such negative constraints, we would  actually need an infinite set of statements to characterize $UG$. This is because it is also the case that ``No language marks past tense by having the speaker eat a banana after uttering the verb,'' and 
``No language requires that listeners look at a square to interpret iterativity,'' {\em etc.} are also true statements about human language. In other words, there are an infinite set of constraints on the set of possible languages.

These examples are of course preposterous, because in practice the constraints are stated in terms of a (usually implicit) universe of discourse. For example, the universe of discourse of linguistic theory does not include bananas, eating, seeing and squares. Therefore, a constraint is only interpretable in the context of a list of positive statements (such as a list of primitive elements like phonological distinctive features, and primitive operations like {\em Move}) which define the universe of discourse of any formal system. 

We see, then, then that a theory which formulates linguistic universals in terms of constraints must {\em also} contain a vocabulary of elements and operations in which those constraints are expressed, or to which they refer. This vocabulary of items and processes is presumably based on empirical observations and inferences. Consider a simpler  alternative.

If our current hypothesis concerning $UG$ is stated only in {\em positive} terms, without {\em negative} constraints, we can achieve a more economical model. The positive terms are just those entities and operations (features, deletions, insertions, {\em Merge}, {\em Move}, {\em etc.}) which have been observed empirically or inferred in the course of model construction. When faced with a phenomenon which is not immediately amenable to modeling using existing elements of the vocabulary, scientific methodology (basically Occam's Razor) guides us. We must
 first try to reduce the new phenomenon to a description in terms of the vocabulary we already have. If this can be shown to be  impossible, only then can we justify expanding the vocabulary.
 
 Thus, a ``constraining approach'' to $UG$, stated in terms of what is disallowed, requires a set of constraints and a vocabulary which defines the universe of discourse in which the constraints are valid.  The alternative proposed here requires only the vocabulary of possible entities and operations, along with  the metatheoretic principle of Occam's Razor. The alternative is thus more elegant and should be preferred.
 
 In more concrete terms this means that our theory of $UG$ should consist of the minimum number of primitives that we need to describe the grammars we have seen. Note that we should not be influenced in our search by preconceived notions of simplicity. For example, if we know that we need hierarchical structure for some phenomena, but there exist other phenomena which are ambiguous as to whether they require flat or hierarchical structure, then we should assume that the ambiguous cases also have hierarchical structure. If our current theory of $UG$  contains an operation which only generates hierarchical structure from the primitive elements, constraints against flat structure will be superfluous. In fact, positive statements like `structures are organized hierarchically' and `all branching is binary' are also superfluous to grammar modeling (assuming they are correct) since they are just a reflection of how structure building operations work. 
 
 The approach advocated here seems to be consistent with that used in science in general. If a physicist observes a constraint on the behavior of a particle, say, then s/he posits a set of properties for that particle from which the observed behavior emerges. The constraint thus has the status of a derivative and not primitive aspect of the theory. The arguments given here for constraints {\em on} grammars can be extended to apply to constraints {\em in} grammars as well, but this discussion is beyond the scope of the current paper (see Reiss 1999).

The issue of `substance abuse' is closely tied to the use of constraints in phonological theory.  Despite the fact that phonologists tend to characterize current debate concerning OT as a question of `rules vs.\ constraints', this is misleading. Many rule-based analyses make use of constraints such as the Obligatory Contour Principle (OCP). Constraints in otherwise rule-based phonologies serve two main purposes. Either they define certain structures as disfavored or illformed, and thus subject to modification by rule; or they are used to block the application of a rule just in case the rules output would be disfavored or illformed.  Work by Paradis (1988) and Calabrese (1988) are typical of the use of constraints as diagnostics for repair of certain structures. The  rule-based account of stress systems presented by
 Halle \& Idsardi (1995)  appeals to `Avoidance Constraints' (422ff) which prevent the application of rules in cases where the rules' output would be a `disfavored' structure. The OCP has been invoked for both of these purposes in a number of papers, most notably McCarthy (1987) and Yip (1988) who makes the following remark: ``The main contribution of the OCP is that it allows us to separate out condition and cure. The OCP is a trigger, a pressure for change \ldots'' (74). 
 
 
 
Given the problems with markedness theory alluded to above, note that in the absence of a theory of disfavoredness, this approach is
 slightly circular: the only real evidence for the disfavored status is that the posited rule appears to be blocked; and the reason for the blocking is that the resultant structure would be disfavored. Halle \& Idsardi point out that certain advantages derive from mixing rules with constraints in the analysis of individual languages. In general, the use of constraints allows us to  formulate simpler rules. However, they note that a fully rule based analyis is in principle always possible---Halle \& Vergnaud (1987) is an example they cite. We propose that considerations of elegance for a theory of $UG$ take precedence over elegance in the analysis of individual languages, and thus the Halle \& Idsardi system, for example,  should be adapted in a way that preserves its mathematical explicitness, while doing away with constraints on
  unattested structures. In general, a  goal of future phonological research should be to take the idea of  rule-based phonology seriously---by avoiding constraints altogether. Such an approach will offer a principled alternative to Optimality Theory and other constraint-based models. In other words, rather than stating simple, but empirically inadequate rules, reinforced by an arsenal of language particular or universal constraints, we should attempt to understand what kind of rules we actually need if we are to do without constraints. An example of this approach is discussed in the next section.
  
\section{{\sc A  result in the formal characterization of $UG$}}


In order to show that there is progress to be made in the characterization of formal properties of $UG$ consider a limited type of condition on rule application (or constraint applicability). Vowel syncope rules are found with (at least) all three of the following types of conditioning:

\begin{itemize}
\item[(8)]{Some  conditions on vowel deletion rules (Odden 1988:462)}
\begin{itemize}
\item[a.]{Delete a vowel unless flanking Cs are identical.}
\item[b.]{Delete a vowel blindly [whatever the flanking Cs are].}
\item[c.]{Delete a vowel only if flanking Cs are identical.}
\end{itemize}
\end{itemize}


\noindent Condition (a) can be restated as `Delete a vowel if flanking Cs are {\em not} identical'.  Thus, 
(a) demands nonidentity and (c) demands identity of segments in  Structural Descriptions (SDs). Phonological 
formalism must therefore have at least enough power to express conditions of nonidentity and identity. These 
conditions  may also be restricted to a given subset of phonological features, such as the set of Place features. 


Autosegmental representation can represent  (c) using linked structures---two $C$-slots may be linked to a single feature tree or matrix. Alternatively,  two slots may  be explicitly linked to separate, but identical trees/matrices.  However,  (a), the requirement of nonidentity, cannot be represented  using just autosegmental notation.  This is because nonidentity can be due to a disagreement with respect to {\em any} feature, and autosegmental notation does not make use of variables. In order to represent conditions of nonidentity Reiss (1999) makes use of a  system of Feature Algebra (FA) incorporating the existential and univeral quantifiers. FA allows the formulation of  conditions that have traditionally been notated as, say, $C_1 \neq C_2$ and $C_1 = C_2$. The conditions are stated here in prose form:


\begin{itemize}\label{cond}
\item[(9)]{Attested conditions of rule application}
{\begin{itemize}
\item[i.]{The  {\sc Nonidentity Condition} (encompasses condition (a)) \\ There exists some feature F, such that $C_1$ and $C_2$ have opposite values for F.}
\item[ii.]{The  {\sc Identity Condition} (encompasses condition (c)) \\ For all features F, $C_1$ and $C_2$ have the same value.}}
\end{itemize}
\end{itemize}

\noindent In both conditions the set of features over which nonidentity or identity is computed may be a subset of the total feature set. For example, an identity condition may be applicable only to the set of Place features in a given rule.


Reiss (1999) applies the FA formalism to data presented  by McCarthy (1986), Yip (1988) and Odden (1986, 1988) in their arguments concerning the status of the Obligatory Contour Principle (OCP) as a principle of grammar. The use of   FA notation has several benefits. First, it  provides us with counterarguments to Yip's claim that the effects of, {\em e.g.}, the {\sc Identity Condition} should not be built into  SDs. Second, it allows us to evaluate the status of constraints like the OCP in light of data conforming to the apparently contradictory conditions (a) and (c). Third, the formalism helps us to discover that two other formally similar conditions are unattested. 


\begin{itemize}
\item[(10)]{\label{v}Unattested conditions on rule application}
\begin{itemize}
\item[i.]{{\sc complete nonidentity condition} \\ For all features F, $C_1$ and $C_2$ have the opposite value for F.}
\item[ii.]{{\sc variable partial identity condition} \\ There exists some feature F, such that $C_1$ and $C_2$ have the same value for F.}
\end{itemize}
\end{itemize}

The {\sc complete nonidentity condition} would allow a rule deleting a vowel only if flanking segments have opposite values for, say,  all Place  features, or even for {\em all} features; for example, `Delete a vowel in the environment $C_1$\underline{\hspace{.15in}}$C_2$ if  $C_1$ is [-anterior, -labial, +dorsal] and $C_2$   
is [+anterior, +labial, -dorsal], or $C_1$ is [+anterior, -labial, +dorsal] and $C_2$   
is [-anterior, +labial, -dorsal], {\em etc}'.



The  {\sc Variable Partial Identity Condition} would allow, say, a rule that deleted a vowel only if flanking consonants have  the  same value for {\em any} feature (perhaps in a given subset of features): `Delete a vowel in the environment $C_1$\underline{\hspace{.15in}}$C_2$ if and only if $C_1$  and $C_2$  are both [$\alpha$anterior], or  [$\alpha$labial], or [$\alpha$dorsal], {\em etc}'. 

It turns out that while these two conditions are apparently unattested in phonology, they are used in the interpretation of binding relations. Thus a careful consideration of the formal requirements of $UG$ can lead to interesting results.
 It should be satisfying enough to get a handle on what we know $UG$ can do, what its formal properties are, without worrying about what it can't. In this sense, positive characterizations of grammars are to be preferred to constraint based ones.
 

\section{{\sc The mirage of enhancement}}
A particulary illustrative combination of what we consider to 
be the 
misuse of substantive considerations and functionalism   can be found in the literature on phonetic 
enhancement and the maximization of contrast ({\em e.g.,} Stevens {\em et al.} 
1986). For 
example, the tendency of three-vowel systems to contain the maximally distinct 
set 
/i,u,a/ is taken as a reflection of a phonological principle demanding the 
`best' use 
of the available acoustic space. Like other claims concerning markedness and UG, 
this 
pattern is no more than a tendency. However, we can show that the view of 
markedness 
as an emergent property, outlined above, can give insight into this statistical 
pattern. 
Imagine a language ${\cal L}_1$ which had the four  vowels /i,u,e,a/. Now we 
know that 
merger of acoustically similar vowels (like /i/ and /e/) is a common diachronic 
process. 
It would not be surprising if a learner constructing ${\cal L}_2$ on the basis 
of data 
from speakers of ${\cal L}_1$ were to fail to acquire a slight distinction and 
end up 
with a three vowel system containing /i,u,a/. However, it is much less likely  
that the 
learner would fail to acquire an acoustically more robust distinction like /u/ 
{\em vs.} /a/ 
and end up with an inventory containing, say /i, u, e/.\footnote{Note that 
`phonetic
substance' may itself indicate how weak the reasoning is in this case: English 
[i], as
well as the other front vowels, is significantly lower than Danish [i]. Why is
the `maximization of contrast' not active at the phonetic level -- precisely the
level which provides the alleged `substance' (perceptual distinctness, in this
case) for the functionalist claim?} So, vowels which are close 
together in the acoustic space are likely to merge diachronically. Vowels which 
are 
acoustically distant are not likely to merge diachronically. The observed 
pattern of 
maximal contrast is thus not built into the phonology, but is an emergent 
property of 
the set of observed phonological systems due to the nature of diachronic 
sound change.


\section{{\sc Functionalism and dysfunctionalism}}
The rise of Optimality Theory has been accompanied by a revival of functionalism
in 
phonology. In fact, there is no necessary connection between OT as a theory of 
computation and functionalist reasoning, and an OT proponent might invoke what we call  the {\em NRA} defense (``Guns don't kill people; people kill people''):  Computational theories  aren't inherently functionalist,  people are functionalist. However, the ease with which functionalist 
ideas 
can be implemented in OT has clearly invited this `functionalist' explosion and may bear on the question of whether or not the theory is sufficiently constrained or even constrainable. Note also that the ``logic'' of functionalism (namely, that {\em all} phenomena are explicable by reference to competition between universal, but  violable, principles) is identical to the logic of OT. In 
this 
section we briefly show that the `substance' orientation of functionalism can be 
turned 
on its head to yield a theory which we will dub `dysfunctionalism'. 
 
Many functionalist theories of grammar can be summarized in almost Manichean 
terms as 
consisting of a struggle between the `competing forces' of ease of articulation 
(what 
is presumed to be `good' for the speaker) and avoidance of ambiguity (what is 
presumed 
to be `good' for the hearer). As an example of the former, consider Kirchner's 
(1997) 
constraint ``{\sc Lazy}---Minimize articulatory effort'' (p.104). For the 
avoidance of 
ambiguity, consider Flemming's (1995)  {\sc  Maintain Contrast} constraints, 
which are 
violated by surface merger of underlying contrasts.

The interplay of what is `good for' the speaker and what is `good for' the 
hearer 
supposedly gives rise to the patterns we see in language: sometimes mergers 
occur and 
the speaker's output is `simplified'--- potentially creating a difficulty for 
the hearer; 
sometimes the speaker maintains  distinctions, perhaps producing a more 
`complex' output, 
thus avoiding ambiguity for the hearer.\footnote{Further evidence for the 
incoherence of the
 functionalist position is the fact that `careless' speech often can lead to 
supposedly complex
outputs such as the stop cluster in [pt]{\em ato} for {\em potato}. Onset stop 
clusters are
 not found in careful speech, so it is surprising, from a functionalist 
perspective, that they
 should be found precisely when the speaker is not putting forth greater 
articulatory effort.}

The problem with this theory is that functionalist principles can be replaced by 
their 
opposites, which we will call `dysfunctionalist' principles, with no significant
change in the set of grammars predicted to exist. Consider 
the following principles, proposed by a linguist with a different view of human 
nature 
than the functionalists have. 


\begin{itemize} 
\item[(11)]{Principles of Dysfunctionalism}\vspace{-.1in}
\end{itemize}
\begin{itemize}
\item[]{{\sc Obfuscate:} merge contrasts, use a small inventory of 
distinctive sounds, {\em etc}.}\vspace{-.1in}
\end{itemize}
\begin{itemize}
\item[]{{\sc No Pain-No Gain:} maintain contrasts, use a large inventory, 
generate allomorphy, {\em etc}.}
\end{itemize}

\noindent Merger,  widely attested in the languages of the world, as well as the oft-proclaimed diachronic principle that 
`change is 
simplification', will be accounted 
for by 
the (dys)functional requirement that one should {\sc Obfuscate}. The failure of 
merger, equally
well attested, and the generally ignored diachronic process of `complexification',  will be attributed to the effects of the {\sc No Pain-No Gain} 
Principle.
The competition of these two `dysfunctionalist' principles will thus lead to the 
exact 
same results as the usually cited functionalist principles. While the ultimate 
question 
of whether human beings are fundamentally lazy, but helpful, or something 
seemingly more 
perverse is intriguing, it hardly seems like investigation into such matters 
should form
the foundation of a theory of phonological computation.\footnote{The
authors would be happy to provide examples -- drawn from the history
of linguistic theory -- of the evolutionary advantages of self-interested 
effort ({\sc No Pain-No Gain}) and {\sc Obfuscate}. We refrain for reasons of 
space, fully
confident that the reader will have no difficulty generating ample evidence on 
his or her
own.}
We propose, therefore, that functionalism 
provides no insight into the nature of grammar. Again, we propose leaching all 
substance 
out of phonology in order to better observe the abstract computational system.

The alternative -- which seems to be the focus of many current developments in 
phonological theory -- seems
clear. Given a sufficiently rich and explicit theory
of the human personality (giving us principles such as `be lazy' and `be helpful 
to the
listener') and the human articulatory and perceptual systems (`phonetic' 
substance),
phonology itself will turn out to be epiphenomenal. While this seems 
considerably less
promising to us, it has clear implications for the research strategy which 
phonologists
should adopt. Phonologists, under such a view, should focus their energies in 
two domains:
phonetics and the empirical explication of fundamental features of the human 
personality (`laziness,'
`helpfulness,' {\em etc}.).

The anti-functionalist stance taken here is, of course, not new. For example, Halle (1975:528), points out that

\begin{quotation} \noindent  Since language is not, in its essence, a means for transmitting [cognitive] information---though no one denies that we constantly use language for this very purpose---then it is hardly surprising to find in languages much ambiguity and redundancy, as well as other properties that are obviously undesirable in a good communication code. 
\end{quotation}


\noindent Halle suggests that it is more fruitful  to conceive of language as a kind of mathematical game than to concern ourselves with the `communicative functions' approach to  studying language. The latter viewpoint  led to such dead ends as the application of formal information theory to natural language. 


\section{{\sc Conclusions}}
We are advocating that phonologists, {\em qua} phonologists, attempt to explain less, but in a deeper way. As we hope to have indicated, empirical results provided by phoneticians and psycholinguists contribute to the development of a substance-free phonology, and we look forward to important cooperation with scholars in these fields. We recognize that only they can provide explanation for many   (E-language) generalizations which are striking in their statistical regularity.\footnote{But see Engstrand 1997ab for arguments that the statistics may be misleading. For example,  the purported markedness of /p/, as evidenced by its relative rarity in voiceless stop inventories, {\em vis-\`{a}-vis} /t/ and /k/, is probably  illusory. The overwhelming majority of the languages  in a database like UPSID (Maddieson, 1984; Maddieson \& Precoda, 1989) lacking a /p/ are found in  Africa. Similarly, the languages of Africa do not `avoid' voiced velar stops, which are also commonly assumed to be marked (see fn.6). ``Thus, it cannot be concluded that velars and bilabials constitute underrepresented members of the respective voiced and voiceless stop series. Although this pattern is to be expected from proposed production and perception constraints, it is largely overridden by areal biases'' (Engstrand 1997a:1).} Since we believe that the focus of phonological theory should be on the cognitive architecture of the computational system, we also believe that the non-substantive aspects of Optimality Theory have been tremendously important for the development of the field. The best of the OT literature is far more explicit about the nature of the assumed computational system than its predecessors often were. The mere existence of such a well-developed  alternative to rule-based phonology is valuable, regardless of specific formal problems ({\em e.g.}, synchronic `chainshifts') or the `substance abuse' found in any particular implementation. However, we have also raised the question of whether constraints are appropriate entities for scientific modeling, since they must always be accompanied by a somewhat redundant positive characterization of a universe of discourse.


\noindent{{\sc References}}

\begin{reflist}

Beckman, J. 1997. Positional faithfulness, positional neutralisation and Shona 
vowel 
Harmony. {\em Phonology} {\bf 14}:1-46.

Bregman, A.\ 1990. {\it Auditory Scene Analysis}. Cambridge, MA: MIT Press.

Burton-Roberts, N.  (this volume) Where and what is phonology? A
representational perspective.    


Calabrese, A. 1988. {\it Towards a theory of phonological alphabets.} Ph.D. dissertation, MIT. 


Chomsky, N. 1986. {\it Knowledge of Language.} Westport, CT: Praeger.


Chomsky, N. 1971. {\it Problems of Knowledge and Freedom}. New York: Random House.


Chomsky, N. and M. Halle. 1968. {\em The Sound Pattern of English}. New York: 
Harper and Row.

Engstrand, O. 1997a. Areal biases in stop paradigms. Papers from {\em Fonetik 97, The Ninth Swedish Phonetics Conference}, held in Ume\aa , May 28-30, 1997. Reports from the Department of
Phonetics, Ume University (PHONUM), 4, 187-190.

Engstrand, O. 1997b. Why are clicks so exclusive? {\em Papers from Fonetik 97, The Ninth Swedish Phonetics Conference}, held in Ume\aa , May 28-30, 1997. Reports from the Department of Phonetics,
Ume University (PHONUM), 4, 191-194.

Flemming, E. 1995. Phonetic detail in phonology: Toward a unified account of assimilation and coarticulation. To appear in K. Suzuki and D. Elzinga (eds.). 
{\em Coyote Papers , Proceedings of the Arizona Phonology Conference 5, Features in Optimality Theory}. University of Arizona, Tucson.
 
Hale, M. To appear. What is output?. In {\it Proceedings of Phonology 2000} M. Halle and B. Vaux (eds.).
                  
Hale, M. Forthcoming. {\em Theory and Method in Historical Linguistics.} Oxford: 
Blackwell.


Hale, M. and C. Reiss. 2000. Substance abuse and dysfunctionalism: Current trends in phonology.  {\it Linguistic Inquiry} 31: 157-169.

Hale, M. and C. Reiss. 1999. Grammar Optimization. To appear in {\em Language Acquisition}.


Halle, M. 1975. Confessio Grammatici. {\it Language} 51:525-35.

Halle, M. \& W. Idsardi. 1995. Stress and metrical structure. In J. Goldsmith (ed.), {\em Handbook of Phonological Theory.} Oxford: Blackwell.



Halle, M. and W. Idsardi. 1997. {\em r}, Hypercorrection and the Elsewhere 
Condition. In 
Roca, I., (ed.). {\em Derivations and Constraints in Phonology,} (331-348). 
Oxford: 
Clarendon Press.

Halle, M. \& J.R. Vergnaud. {\it An essay on stress.} Cambridge, MA: MIT Press.


Hellberg, S. 1980. Apparent Naturalness in Faroese Phonology. {\em Nordic 
Journal of Linguistics} 3:1-24.

Hoffman, D. D. 1998. {\it Visual intelligence}. New York, NY: Norton.

Keating, P. 1988. Underspecification in phonetics. {\em Phonology} 5: 275-292.


Kirchner, R. 1997. Contrastiveness and faithfulness. {\em Phonology} {\bf 
14}:83-111.

Maddieson, I. 1984. Patterns of sounds. Cambridge: Cambridge University Press.


Maddieson, I. and Precoda K. 1989. Updating UPSID. Journal of the Acoustical Society of America, Suppl. 1, Vol. 86, S19.

McCarthy, J. 1996. Remarks on Phonological Opacity in Optimality Theory. In {\em 
Proceedings of the Second Colloquium on Afro-Asiatic Linguistics.} J. Lecarme, 
J. Lowenstamm and U. Schlonsky, eds. 215-243.

McCarthy, J. 1993. A case of surface rule inversion. {\em Canadian Journal of 
Linguistics} {\bf 38}:169-95.


McCarthy, J. 1988. Feature geometry and dependency: a review, \textit{Phonetica} 45:84-108.


McCarthy, J. 1986. OCP effects: Gemination and antigemination. {\it Linguistic Inquiry} 17:207-263.

McCarthy, J. and A. Prince. 1995. Faithfulness and Reduplicative Identity. {\em 
ROA-60}

LaCharit\'{e}, D. and C. Paradis. 1993. Introduction: The emergence of 
constraints in 
Generative Phonology and a comparison of three current constraint-based models. 
{\em Canadian Journal of Linguistics} {\bf 38}:127-51.

Odden, D. 1988. Antiantigemination and the OCP. {\it Linguistic Inquiry} 19:451-475.

Ohala, J. 1998. A Bibliography of the Phonetics of Sound Change. Department of Linguistics, UC Berkeley.

Ohala, J. 1990. The phonetics and phonology of aspects of assimilation. In J. Kingston and M. Beckman (eds.), {\em Papers in Laboratory Phonology I: Between the Grammar and Physics of Speech.} Cambridge: Cambridge University Press.

Paradis, C. 1988. On constraints and repair strategies. {\it LR} 6: 71-97.


Prince, A. and P. Smolensky. 1993. \textit{Optimality Theory: Constraint Interaction in Generative Grammar}. 
Technical Report Rutgers Center for Cognitive Science, Rutgers University, New Brunswick, N.J.


Pylyshyn, Z. 1984. \textit{Computation and cognition: toward a foundation for
cognitive science.} MIT Press, Cambridge, MA.

Pylyshyn, Z. 1973. On the role of competence theories in cognitive psychology. {\it Journal of Psycholinguistic 
Research} 2:21-50.

Reiss, C. 1999. Philosophical and Empirical Reasons to Ban Constraints from Linguistic 
Theory. Ms. Concordia University.

Reiss, C. 1997. Unifying the interpretation of structural descriptions. {\em WCCFL 15}:413-27.

Reiss, C. 1996. Deriving an Implicational Universal in a constrained OT grammar. {\em NELS 26}:303-17.

Sapir, E. 1925. Sound Patterns in Language. {\it Language} 1:37-51. Reprinted in Joos, Martin, ed., 
1957, {\em Readings in Linguistics}:19-25. Washington: American Council of Learned Societies.

Steriade, D. 1997. Markedness and neutralization of laryngeal contrasts. Talk presented at Harvard University.

Stevens, K.,  S. J. Keyser,  and H. Kawasaki. 1986. Toward a phonetic and 
phonological theory of redundant features. In J. Perkell and D. Klatt (eds.) {\em Symposium 
on invariance and variability of speech processes}. Hillsdale: Erlbaum.


Yip, M. 1988. The Obligatory Contour Principle and Phonological Rules: A Loss of Identity. {\it Linguistic Inquiry} 19: 65-100.
\end{reflist}


%\clearpage

%\begingroup
%\parindent 0pt
%\parskip 1ex
%\def\enotesize{\normalsize}
%\theendnotes
%\endgroup


\end{document}


\clearpage

\noindent Authors' addresses:

Mark Hale

Department of Classics, Modern Languages, and Linguistics

Concordia University

1455 de Maisonneuve Blvd.\ W.

Montr\'{e}al, Qu\'{e}bec, Canada

H3G 1M8

hale1@alcor.concordia.ca
\vspace{.2in}

Charles Reiss

Department of Classics, Modern Languages, and Linguistics

Concordia University

1455 de Maisonneuve Blvd.\ W.

Montr\'{e}al, Qu\'{e}bec, Canada

H3G 1M8

reiss@alcor.concordia.ca







\clearpage

\setcounter{figure}{0}

\begin{figure}[htb]
\begin{center}
\epsfig{figure=illusion-1b.eps}
\end{center}
\caption{Triangle constructed by  visual system.}
\end{figure}

